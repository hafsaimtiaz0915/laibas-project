{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TFT V2 Training â€” Properly (8-Year Encoder)\n",
        "\n",
        "**Before running:** Upload `Data/tft/runs/20251218T163716Z/tft_training_data_v2.csv` to Google Drive as `/MyDrive/Properly/tft_training_data_v2.csv`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 1 â€” Setup & GPU Check\n",
        "!pip install -q pytorch-forecasting==1.5.0 lightning==2.4.0\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import subprocess, torch\n",
        "subprocess.run([\"bash\", \"-lc\", \"nvidia-smi -L && nvidia-smi\"], check=False)\n",
        "\n",
        "assert torch.cuda.is_available(), \"FAIL: CUDA GPU not detected - go to Runtime > Change runtime type > GPU\"\n",
        "gpu_name = torch.cuda.get_device_name(0)\n",
        "print(\"GPU:\", gpu_name)\n",
        "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 2 â€” Load Data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "DATA_PATH = \"/content/drive/MyDrive/Properly/tft_training_data_v2.csv\"\n",
        "data = pd.read_csv(DATA_PATH, low_memory=False)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"LOADED DATA\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Rows:\", len(data))\n",
        "print(\"Columns:\", len(data.columns))\n",
        "print(\"\\nColumn names:\", list(data.columns))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 3 â€” Config + Data Quality Gates\n",
        "# ============================================================\n",
        "# TRAINING CONFIGURATION â€” 8-YEAR ENCODER\n",
        "# ============================================================\n",
        "PRED_LEN_MONTHS = 12        # Forecast horizon: 12 months forward\n",
        "ENCODER_LEN_MONTHS = 96     # Lookback: 8 YEARS (96 months) of history\n",
        "MIN_GROUP_HISTORY = 24      # Cold-start filter: need at least 2 years\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Encoder length: {ENCODER_LEN_MONTHS} months (8 years)\")\n",
        "print(f\"Prediction horizon: {PRED_LEN_MONTHS} months\")\n",
        "print(f\"Min group history: {MIN_GROUP_HISTORY} months\")\n",
        "\n",
        "# ============================================================\n",
        "# HARD GATES â€” Training stops if these fail\n",
        "# ============================================================\n",
        "\n",
        "# Gate 1: Required columns\n",
        "required_cols = [\"time_idx\", \"group_id\", \"median_price\", \"median_rent\", \"units_completing\"]\n",
        "missing = [c for c in required_cols if c not in data.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"ðŸ›‘ GATE FAIL: Missing required columns: {missing}\")\n",
        "print(\"âœ… Gate 1: All required columns present\")\n",
        "\n",
        "# Gate 2: units_completing must be non-trivial\n",
        "uc = pd.to_numeric(data[\"units_completing\"], errors=\"coerce\").fillna(0)\n",
        "pct_nonzero = (uc > 0).sum() / len(data) * 100\n",
        "print(f\"   units_completing: {pct_nonzero:.1f}% rows > 0\")\n",
        "if pct_nonzero < 5:\n",
        "    raise ValueError(f\"ðŸ›‘ GATE FAIL: units_completing is mostly zeros ({pct_nonzero:.1f}%)\")\n",
        "print(\"âœ… Gate 2: units_completing has signal\")\n",
        "\n",
        "# Gate 3: Both OffPlan and Ready should exist\n",
        "if \"reg_type\" in data.columns:\n",
        "    reg_types = set(data[\"reg_type\"].astype(str).unique())\n",
        "    if \"OffPlan\" not in reg_types or \"Ready\" not in reg_types:\n",
        "        print(f\"âš ï¸  WARNING: reg_type={reg_types}. Expected both OffPlan and Ready.\")\n",
        "    else:\n",
        "        print(\"âœ… Gate 3: Both OffPlan and Ready present\")\n",
        "\n",
        "print(\"\\nâœ… ALL GATES PASSED\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 4 â€” Cold Start Filter + Feature Engineering\n",
        "print(\"=\" * 60)\n",
        "print(\"COLD START FILTER\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Remove groups with insufficient history\n",
        "group_lengths = data.groupby(\"group_id\")[\"time_idx\"].count()\n",
        "short_groups = group_lengths[group_lengths < MIN_GROUP_HISTORY].index.tolist()\n",
        "print(f\"Groups with < {MIN_GROUP_HISTORY} months: {len(short_groups)}\")\n",
        "\n",
        "if short_groups:\n",
        "    before = len(data)\n",
        "    data = data[~data[\"group_id\"].isin(short_groups)]\n",
        "    after = len(data)\n",
        "    print(f\"Filtered: {before:,} â†’ {after:,} rows ({before - after:,} removed)\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FEATURE ENGINEERING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Ensure month/quarter are categorical strings\n",
        "data[\"month\"] = data[\"month\"].astype(int).astype(str)\n",
        "data[\"quarter\"] = data[\"quarter\"].astype(int).astype(str)\n",
        "\n",
        "# Ensure sin/cos exist\n",
        "if \"month_sin\" not in data.columns:\n",
        "    m = data[\"month\"].astype(int)\n",
        "    data[\"month_sin\"] = np.sin(2 * np.pi * m / 12.0)\n",
        "    data[\"month_cos\"] = np.cos(2 * np.pi * m / 12.0)\n",
        "    print(\"Created month_sin/month_cos\")\n",
        "\n",
        "# Static categoricals\n",
        "static_categoricals = []\n",
        "for c in [\"area_name\", \"property_type\", \"bedroom\", \"reg_type\", \"developer_brand_label\", \"developer_umbrella\"]:\n",
        "    if c in data.columns:\n",
        "        data[c] = data[c].fillna(\"UNKNOWN\").astype(str)\n",
        "        static_categoricals.append(c)\n",
        "\n",
        "print(\"Static categoricals:\", static_categoricals)\n",
        "\n",
        "# has_actual_rent flag (helps model understand OffPlan groups)\n",
        "data[\"has_actual_rent\"] = data.groupby(\"group_id\")[\"median_rent\"].transform(\n",
        "    lambda x: (x.notna() & (x > 0)).any()\n",
        ").astype(int)\n",
        "print(f\"Groups WITH actual rent: {data.loc[data['has_actual_rent']==1, 'group_id'].nunique():,}\")\n",
        "print(f\"Groups WITHOUT rent: {data.loc[data['has_actual_rent']==0, 'group_id'].nunique():,}\")\n",
        "\n",
        "# Sort by group + time\n",
        "data = data.sort_values([\"group_id\", \"time_idx\"]).reset_index(drop=True)\n",
        "\n",
        "# Fill targets per group\n",
        "data[\"median_price\"] = data.groupby(\"group_id\")[\"median_price\"].transform(lambda x: x.ffill().bfill())\n",
        "data[\"median_rent\"] = data.groupby(\"group_id\")[\"median_rent\"].transform(lambda x: x.ffill().bfill()).fillna(0)\n",
        "\n",
        "# Identify numeric columns\n",
        "protected = set([\"group_id\", \"time_idx\", \"median_price\", \"median_rent\", \"month\", \"quarter\"] + static_categoricals)\n",
        "numeric_cols = [c for c in data.columns if c not in protected and pd.api.types.is_numeric_dtype(data[c])]\n",
        "\n",
        "# Clean numeric columns\n",
        "data[numeric_cols] = data[numeric_cols].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "assert data[\"median_price\"].notna().all(), \"median_price still has NaNs\"\n",
        "print(f\"\\nâœ… Ready: {data['group_id'].nunique():,} groups, {len(data):,} rows\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 5 â€” Train/Val Split\n",
        "max_time = int(data[\"time_idx\"].max())\n",
        "cutoff = max_time - PRED_LEN_MONTHS\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"TRAIN/VAL SPLIT\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Data time range: 0 to {max_time} (time_idx)\")\n",
        "print(f\"Forecast horizon: {PRED_LEN_MONTHS} months\")\n",
        "print(f\"Encoder lookback: {ENCODER_LEN_MONTHS} months (8 years)\")\n",
        "print(f\"Cutoff for split: {cutoff}\")\n",
        "print(f\"  â†’ Train: time_idx <= {cutoff}\")\n",
        "print(f\"  â†’ Val:   time_idx > {cutoff} (last {PRED_LEN_MONTHS} months)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 6 â€” Create TimeSeriesDataSet\n",
        "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
        "from pytorch_forecasting.data import GroupNormalizer, MultiNormalizer\n",
        "from pytorch_forecasting.metrics import QuantileLoss, MultiLoss\n",
        "\n",
        "# Known reals: features we CAN generate into the future\n",
        "known_reals = [\"time_idx\", \"month_sin\", \"month_cos\", \"units_completing\"]\n",
        "\n",
        "# Unknown reals: features only observed historically\n",
        "unknown_reals = [c for c in numeric_cols if c not in known_reals]\n",
        "if \"has_actual_rent\" not in unknown_reals:\n",
        "    unknown_reals.append(\"has_actual_rent\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FEATURE CLASSIFICATION\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Known reals (can forecast forward):\", known_reals)\n",
        "print(f\"Unknown reals: {len(unknown_reals)} columns\")\n",
        "\n",
        "training = TimeSeriesDataSet(\n",
        "    data[data[\"time_idx\"] <= cutoff],\n",
        "    time_idx=\"time_idx\",\n",
        "    target=[\"median_price\", \"median_rent\"],\n",
        "    group_ids=[\"group_id\"],\n",
        "    min_encoder_length=12,              # Minimum 1 year lookback\n",
        "    max_encoder_length=ENCODER_LEN_MONTHS,  # Maximum 8 YEARS lookback\n",
        "    min_prediction_length=1,\n",
        "    max_prediction_length=PRED_LEN_MONTHS,\n",
        "    static_categoricals=static_categoricals,\n",
        "    time_varying_known_categoricals=[\"month\", \"quarter\"],\n",
        "    time_varying_known_reals=known_reals,\n",
        "    time_varying_unknown_reals=unknown_reals,\n",
        "    target_normalizer=MultiNormalizer([\n",
        "        GroupNormalizer(groups=[\"group_id\"], transformation=\"softplus\"),\n",
        "        GroupNormalizer(groups=[\"group_id\"], transformation=\"softplus\"),\n",
        "    ]),\n",
        "    add_relative_time_idx=True,\n",
        "    add_target_scales=True,\n",
        "    add_encoder_length=True,\n",
        "    allow_missing_timesteps=True,\n",
        ")\n",
        "\n",
        "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
        "\n",
        "print(f\"\\nâœ… Training samples: {len(training):,}\")\n",
        "print(f\"âœ… Validation samples: {len(validation):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 7 â€” Create Model & DataLoaders\n",
        "import lightning.pytorch as pl\n",
        "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "os.makedirs(\"/content/checkpoints\", exist_ok=True)\n",
        "\n",
        "batch_size = 512\n",
        "train_dl = training.to_dataloader(train=True, batch_size=batch_size, num_workers=2)\n",
        "val_dl = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=2)\n",
        "\n",
        "tft = TemporalFusionTransformer.from_dataset(\n",
        "    training,\n",
        "    hidden_size=64,\n",
        "    attention_head_size=4,\n",
        "    dropout=0.1,\n",
        "    hidden_continuous_size=32,\n",
        "    lstm_layers=2,\n",
        "    output_size=[7, 7],  # 7 quantiles per target\n",
        "    loss=MultiLoss([QuantileLoss(), QuantileLoss()]),\n",
        "    learning_rate=1e-3,\n",
        "    reduce_on_plateau_patience=4,\n",
        ")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"MODEL CREATED\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Parameters: {tft.size()/1e6:.2f}M\")\n",
        "print(f\"Batch size: {batch_size}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 8 â€” Train Model\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=100,\n",
        "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
        "    devices=1,\n",
        "    precision=\"bf16-mixed\" if torch.cuda.is_available() else 32,\n",
        "    gradient_clip_val=0.1,\n",
        "    callbacks=[\n",
        "        EarlyStopping(monitor=\"val_loss\", patience=10, mode=\"min\"),\n",
        "        ModelCheckpoint(\n",
        "            dirpath=\"/content/checkpoints/\",\n",
        "            filename=\"tft-{epoch:02d}-{val_loss:.4f}\",\n",
        "            save_top_k=3,\n",
        "            monitor=\"val_loss\",\n",
        "            every_n_epochs=1,\n",
        "        ),\n",
        "    ],\n",
        "    enable_progress_bar=True,\n",
        ")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"TRAINING: {ENCODER_LEN_MONTHS}-month encoder (8 years), {PRED_LEN_MONTHS}-month horizon\")\n",
        "print(\"=\" * 60)\n",
        "trainer.fit(tft, train_dataloaders=train_dl, val_dataloaders=val_dl)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 9 â€” Evaluate & Save Checkpoint\n",
        "import shutil, glob\n",
        "\n",
        "best_ckpt = trainer.checkpoint_callback.best_model_path\n",
        "print(\"Best checkpoint:\", best_ckpt)\n",
        "\n",
        "# Load best model and compute validation metrics\n",
        "best_model = TemporalFusionTransformer.load_from_checkpoint(best_ckpt)\n",
        "predictions = best_model.predict(val_dl, mode=\"prediction\", return_y=True)\n",
        "\n",
        "y_true = predictions.y[0]\n",
        "y_pred = predictions.output\n",
        "\n",
        "price_mae = (y_pred[..., 0] - y_true[..., 0]).abs().mean().item()\n",
        "rent_mae = (y_pred[..., 1] - y_true[..., 1]).abs().mean().item()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"VALIDATION RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Price MAE: {price_mae:.2f} AED/sqft\")\n",
        "print(f\"Rent MAE: {rent_mae:.2f} AED/year\")\n",
        "\n",
        "# Save to Drive\n",
        "out_dir = \"/content/drive/MyDrive/Properly/checkpoints_v2/\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "shutil.copy(best_ckpt, os.path.join(out_dir, \"tft_best_v2.ckpt\"))\n",
        "for p in glob.glob(\"/content/checkpoints/*.ckpt\"):\n",
        "    shutil.copy(p, out_dir)\n",
        "\n",
        "print(f\"\\nâœ… Checkpoint saved to: {out_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 10 â€” Generate Training Manifest (for inference compatibility)\n",
        "manifest = {\n",
        "    \"trained_at\": datetime.utcnow().isoformat() + \"Z\",\n",
        "    \"data_source\": DATA_PATH,\n",
        "    \"rows_after_filter\": len(data),\n",
        "    \"groups_after_filter\": int(data[\"group_id\"].nunique()),\n",
        "    \n",
        "    \"horizon\": {\n",
        "        \"pred_len_months\": PRED_LEN_MONTHS,\n",
        "        \"encoder_len_months\": ENCODER_LEN_MONTHS,\n",
        "        \"min_group_history\": MIN_GROUP_HISTORY,\n",
        "    },\n",
        "    \n",
        "    \"group_id_definition\": {\n",
        "        \"source\": \"V2 builder: area_id_property_type_bedroom_reg_type\",\n",
        "        \"example\": data[\"group_id\"].iloc[0] if len(data) > 0 else None,\n",
        "    },\n",
        "    \n",
        "    \"features\": {\n",
        "        \"static_categoricals\": static_categoricals,\n",
        "        \"time_varying_known_categoricals\": [\"month\", \"quarter\"],\n",
        "        \"time_varying_known_reals\": known_reals,\n",
        "        \"time_varying_unknown_reals_count\": len(unknown_reals),\n",
        "    },\n",
        "    \n",
        "    \"targets\": [\"median_price\", \"median_rent\"],\n",
        "    \n",
        "    \"validation_metrics\": {\n",
        "        \"price_mae\": round(price_mae, 2),\n",
        "        \"rent_mae\": round(rent_mae, 2),\n",
        "    },\n",
        "    \n",
        "    \"inference_contract\": {\n",
        "        \"units_completing\": {\n",
        "            \"type\": \"known_future_real\",\n",
        "            \"generation\": \"MUST compute from Projects.csv handover schedule\",\n",
        "            \"warning\": \"DO NOT use rolling average - will degrade forecasts\",\n",
        "        }\n",
        "    },\n",
        "    \n",
        "    \"checkpoint\": \"tft_best_v2.ckpt\",\n",
        "}\n",
        "\n",
        "manifest_path = os.path.join(out_dir, \"training_manifest.json\")\n",
        "with open(manifest_path, \"w\") as f:\n",
        "    json.dump(manifest, f, indent=2)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"TRAINING COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Checkpoint: {out_dir}tft_best_v2.ckpt\")\n",
        "print(f\"Manifest: {manifest_path}\")\n",
        "print(\"\\nManifest contents:\")\n",
        "print(json.dumps(manifest, indent=2))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
